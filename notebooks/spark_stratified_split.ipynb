{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvvJu+oyscJwAZNKu1W0vO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanina-Kutovaya/GNN/blob/main/notebooks/spark_stratified_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция stratified_split для работы с большими данными в PySpark для модели CatBoost"
      ],
      "metadata": {
        "id": "VdwjIxC9apbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Список тестов из класса ```TestStratifiedSplit```\n",
        "\n",
        "Ниже приведен список всех тестовых методов из класса TestStratifiedSplit, с краткими описаниями их назначения и проверяемых сценариев.\n",
        "\n",
        "1. Основные сценарии разбиения\n",
        "  - ```test_stratified_split_normal```\n",
        "  Проверяет нормальное разбиение на ```train/val/test``` с тремя классами и стандартными пропорциями (например, ```0.6:0.2:0.2```). Убеждается, что данные распределены пропорционально по классам и временные столбцы удалены.\n",
        "  - ```test_stratified_split_no_val```\n",
        "  Проверяет случай, когда ```val_ratio = 0```. Убеждается, что ```val_data``` — пустой DataFrame, а остальные выборки корректно заполнены.\n",
        "  - ```test_stratified_split_no_test```\n",
        "  Проверяет случай, когда ```test_ratio = 0```. Убеждается, что ```test_data``` — пустой DataFrame, а остальные выборки корректно заполнены.\n",
        "2. Граничные случаи и округление\n",
        "  - ```test_small_class_sizes```\n",
        "  Проверяет корректность округления при малых размерах классов. Например, если класс содержит всего 1 элемент, а доля составляет 0.5, то он попадает в остаток (например, в ```test```).\n",
        "3. Обработка ошибок\n",
        "  - ```test_invalid_ratio_sum```\n",
        "  Проверяет, что функция выбрасывает ошибку ```AssertionError```, если сумма долей - ```train_ratio + val_ratio + test_ratio ≠ 1.0```.\n",
        "  - ```test_missing_label_column```\n",
        "  Проверяет, что функция выбрасывает ошибку ```ValueError```, если указанный ```label_col``` отсутствует в DataFrame.\n",
        "4. Воспроизводимость\n",
        "  - ```test_reproducibility```\n",
        "  Проверяет, что при одинаковом ```seed``` результаты разбиения воспроизводятся. Убеждается, что повторный запуск с тем же ```seed``` дает идентичные выборки."
      ],
      "metadata": {
        "id": "y5HvTX7Fiq-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Что проверяют эти тесты?\n",
        "\n",
        "- __Корректность разбиения:__ Пропорциональное распределение классов в ```train/val/test```.\n",
        "- __Удаление временных столбцов:__ Отсутствие служебных столбцов (```__temp_rand__```, ```__temp_row_num__``` и т.д.) в результатах.\n",
        "- __Граничные случаи:__ Обработка ```val_ratio=0```, ```test_ratio=0```, малых классов.\n",
        "- __Исключения:__ Проверка выбросов ошибок при некорректных входных данных.\n",
        "- __Воспроизводимость:__  Идентичные результаты при одинаковом ```seed```\n",
        "\n",
        "Эти тесты полностью покрывают основные сценарии использования функции ```stratified_split```, включая стратификацию, обработку ошибок и воспроизводимость."
      ],
      "metadata": {
        "id": "KsjnZ55wkbe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install = False\n",
        "if install:\n",
        "  # Установить Spark 3.4 с Scala 2.12\n",
        "  !pip install -q pyspark==3.4.0 catboost==1.2.8\n",
        "\n",
        "  # Перезапустить среду после установки\n",
        "  import os\n",
        "  os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "3axodC2ha3GE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from pyspark.sql import SparkSession, DataFrame, Window\n",
        "from pyspark.sql.functions import col, rand, row_number, when\n",
        "from typing import Tuple\n",
        "\n",
        "def stratified_split(\n",
        "    df: DataFrame,\n",
        "    label_col: str,\n",
        "    train_ratio: float = 0.6,\n",
        "    val_ratio: float = 0.2,\n",
        "    test_ratio: float = 0.2,\n",
        "    seed: int = 42\n",
        ") -> Tuple[DataFrame, DataFrame, DataFrame]:\n",
        "    \"\"\"\n",
        "    Стратифицированное разделение данных на train/val/test с использованием оконных функций.\n",
        "\n",
        "    Parameters:\n",
        "        df (DataFrame): Исходный DataFrame.\n",
        "        label_col (str): Название столбца с метками классов.\n",
        "        train_ratio (float): Доля обучающей выборки.\n",
        "        val_ratio (float): Доля валидационной выборки.\n",
        "        test_ratio (float): Доля тестовой выборки.\n",
        "        seed (int): Сид для генерации случайных чисел.\n",
        "\n",
        "    Returns:\n",
        "        tuple[DataFrame, DataFrame, DataFrame]: train_data, val_data, test_data.\n",
        "    \"\"\"\n",
        "    # Проверка суммы долей\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9, \"Сумма долей должна быть равна 1.0\"\n",
        "\n",
        "    # Проверка наличия столбца меток\n",
        "    if label_col not in df.columns:\n",
        "        raise ValueError(f\"Столбец '{label_col}' отсутствует в DataFrame.\")\n",
        "\n",
        "    # Добавляем случайное число для сортировки внутри групп\n",
        "    df = df.withColumn(\"__temp_rand__\", rand(seed))\n",
        "\n",
        "    # Окно для нумерации строк внутри групп по случайному числу\n",
        "    window_spec = Window.partitionBy(label_col).orderBy(\"__temp_rand__\")\n",
        "\n",
        "    # Добавляем номер строки в группе, начиная с 1\n",
        "    df_ranked = df.withColumn(\"__temp_row_num__\", row_number().over(window_spec))\n",
        "\n",
        "    # Вычисляем общее количество строк в каждой группе\n",
        "    group_counts = df_ranked.groupBy(label_col).count().withColumnRenamed(\"count\", \"__temp_total__\")\n",
        "\n",
        "    # Присоединяем количество строк к исходному DataFrame\n",
        "    df_with_counts = df_ranked.join(group_counts, on=label_col)\n",
        "\n",
        "    # Вычисляем пороги для train и val\n",
        "    train_threshold = (col(\"__temp_total__\") * train_ratio).cast(\"int\")\n",
        "    val_threshold = (col(\"__temp_total__\") * (train_ratio + val_ratio)).cast(\"int\")\n",
        "\n",
        "    # Присваиваем метки частей\n",
        "    df_partitioned = df_with_counts.withColumn(\n",
        "        \"__temp_partition__\",\n",
        "        when(col(\"__temp_row_num__\") <= train_threshold, \"train\")\n",
        "             .when(col(\"__temp_row_num__\") <= val_threshold, \"val\")\n",
        "             .otherwise(\"test\")\n",
        "    )\n",
        "\n",
        "    # Фильтруем по меткам и убираем временные столбцы\n",
        "    train_data = df_partitioned.filter(col(\"__temp_partition__\") == \"train\").drop(\n",
        "        \"__temp_rand__\", \"__temp_row_num__\", \"__temp_total__\", \"__temp_partition__\"\n",
        "    )\n",
        "    val_data = df_partitioned.filter(col(\"__temp_partition__\") == \"val\").drop(\n",
        "        \"__temp_rand__\", \"__temp_row_num__\", \"__temp_total__\", \"__temp_partition__\"\n",
        "    )\n",
        "    test_data = df_partitioned.filter(col(\"__temp_partition__\") == \"test\").drop(\n",
        "        \"__temp_rand__\", \"__temp_row_num__\", \"__temp_total__\", \"__temp_partition__\"\n",
        "    )\n",
        "\n",
        "    # Если val_ratio или test_ratio равны нулю, возвращаем пустой DataFrame\n",
        "    if val_ratio == 0:\n",
        "        val_data = df.sparkSession.createDataFrame(df.sparkSession.sparkContext.emptyRDD(), df.schema)\n",
        "    if test_ratio == 0:\n",
        "        test_data = df.sparkSession.createDataFrame(df.sparkSession.sparkContext.emptyRDD(), df.schema)\n",
        "\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "\n",
        "class TestStratifiedSplit(unittest.TestCase):\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        cls.spark = SparkSession.builder \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .appName(\"TestStratifiedSplit\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        cls.spark.stop()\n",
        "\n",
        "    def create_test_data(self, class_counts: dict = None) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Создаёт тестовый DataFrame с заданным количеством элементов в каждом классе.\n",
        "        Пример: {\"A\": 10, \"B\": 15, \"C\": 5}\n",
        "        \"\"\"\n",
        "        if class_counts is None:\n",
        "            class_counts = {\"A\": 10, \"B\": 15}\n",
        "        data = []\n",
        "        for label, count in class_counts.items():\n",
        "            data.extend([(label,) for _ in range(count)])\n",
        "        return self.spark.createDataFrame(data, [\"label\"])\n",
        "\n",
        "    def check_partition_sizes(self, df: DataFrame, expected_counts: dict):\n",
        "        \"\"\"\n",
        "        Проверяет, что количество элементов по классам в выборке соответствует ожидаемому.\n",
        "        \"\"\"\n",
        "        counts = df.groupBy(\"label\").count().rdd.collectAsMap()\n",
        "        for label, expected in expected_counts.items():\n",
        "            self.assertEqual(counts.get(label, 0), expected)\n",
        "\n",
        "    def test_stratified_split_normal(self):\n",
        "        \"\"\"\n",
        "        Проверяет нормальное разбиение на train/val/test с тремя классами.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data({\"A\": 10, \"B\": 15, \"C\": 5})\n",
        "        train_ratio, val_ratio, test_ratio = 0.6, 0.2, 0.2\n",
        "        train_data, val_data, test_data = stratified_split(df, \"label\", train_ratio, val_ratio, test_ratio)\n",
        "\n",
        "        # Проверка размеров\n",
        "        self.check_partition_sizes(train_data, {\"A\": 6, \"B\": 9, \"C\": 3})\n",
        "        self.check_partition_sizes(val_data, {\"A\": 2, \"B\": 3, \"C\": 1})\n",
        "        self.check_partition_sizes(test_data, {\"A\": 2, \"B\": 3, \"C\": 1})\n",
        "\n",
        "        # Проверка удаления временных столбцов\n",
        "        temp_cols = [\"__temp_rand__\", \"__temp_row_num__\", \"__temp_total__\", \"__temp_partition__\"]\n",
        "        for col_name in temp_cols:\n",
        "            self.assertNotIn(col_name, train_data.columns)\n",
        "            self.assertNotIn(col_name, val_data.columns)\n",
        "            self.assertNotIn(col_name, test_data.columns)\n",
        "\n",
        "    def test_stratified_split_no_val(self):\n",
        "        \"\"\"\n",
        "        Проверяет случай, когда val_ratio = 0.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data({\"A\": 10, \"B\": 15})\n",
        "        train_ratio, val_ratio, test_ratio = 0.8, 0.0, 0.2\n",
        "        train_data, val_data, test_data = stratified_split(df, \"label\", train_ratio, val_ratio, test_ratio)\n",
        "\n",
        "        self.assertEqual(val_data.count(), 0)\n",
        "        self.check_partition_sizes(train_data, {\"A\": 8, \"B\": 12})\n",
        "        self.check_partition_sizes(test_data, {\"A\": 2, \"B\": 3})\n",
        "\n",
        "    def test_stratified_split_no_test(self):\n",
        "        \"\"\"\n",
        "        Проверяет случай, когда test_ratio = 0.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data({\"A\": 10, \"B\": 15})\n",
        "        train_ratio, val_ratio, test_ratio = 0.7, 0.3, 0.0\n",
        "        train_data, val_data, test_data = stratified_split(df, \"label\", train_ratio, val_ratio, test_ratio)\n",
        "\n",
        "        self.assertEqual(test_data.count(), 0)\n",
        "        self.check_partition_sizes(train_data, {\"A\": 7, \"B\": 10})\n",
        "        self.check_partition_sizes(val_data, {\"A\": 3, \"B\": 5})\n",
        "\n",
        "    def test_invalid_ratio_sum(self):\n",
        "        \"\"\"\n",
        "        Проверяет, что функция выбрасывает ошибку при некорректной сумме долей.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data()\n",
        "        with self.assertRaises(AssertionError):\n",
        "            stratified_split(df, \"label\", train_ratio=0.5, val_ratio=0.5, test_ratio=0.1)\n",
        "\n",
        "    def test_missing_label_column(self):\n",
        "        \"\"\"\n",
        "        Проверяет, что функция выбрасывает ошибку при отсутствии указания label_col.\n",
        "        \"\"\"\n",
        "        df = self.spark.createDataFrame([(1,), (2,)], [\"value\"])\n",
        "        with self.assertRaises(ValueError):\n",
        "            stratified_split(df, \"label\", train_ratio=0.6)\n",
        "\n",
        "    def test_small_class_sizes(self):\n",
        "        \"\"\"\n",
        "        Проверяет корректность округления при малых размерах классов.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data({\"A\": 1, \"B\": 2})\n",
        "        train_ratio, val_ratio, test_ratio = 0.5, 0.25, 0.25\n",
        "        train_data, val_data, test_data = stratified_split(df, \"label\", train_ratio, val_ratio, test_ratio)\n",
        "\n",
        "        self.check_partition_sizes(train_data, {\"A\": 0, \"B\": 1})  # 1 * 0.5 = 0.5 → 0\n",
        "        self.check_partition_sizes(val_data, {\"A\": 0, \"B\": 0})    # 1 * 0.25 = 0.25 → 0\n",
        "        self.check_partition_sizes(test_data, {\"A\": 1, \"B\": 1})  # Остаток\n",
        "\n",
        "    def test_reproducibility(self):\n",
        "        \"\"\"\n",
        "        Проверяет воспроизводимость при одинаковом seed.\n",
        "        \"\"\"\n",
        "        df = self.create_test_data({\"A\": 10, \"B\": 15})\n",
        "        train1, val1, test1 = stratified_split(df, \"label\", seed=42)\n",
        "        train2, val2, test2 = stratified_split(df, \"label\", seed=42)\n",
        "\n",
        "        self.assertEqual(train1.count(), train2.count())\n",
        "        self.assertEqual(val1.count(), val2.count())\n",
        "        self.assertEqual(test1.count(), test2.count())\n",
        "\n",
        "        # Сравнение содержимого\n",
        "        train1_sorted = train1.sort(\"label\")\n",
        "        train2_sorted = train2.sort(\"label\")\n",
        "        self.assertTrue(train1_sorted.exceptAll(train2_sorted).isEmpty())\n",
        "\n",
        "        val1_sorted = val1.sort(\"label\")\n",
        "        val2_sorted = val2.sort(\"label\")\n",
        "        self.assertTrue(val1_sorted.exceptAll(val2_sorted).isEmpty())\n",
        "\n",
        "        test1_sorted = test1.sort(\"label\")\n",
        "        test2_sorted = test2.sort(\"label\")\n",
        "        self.assertTrue(test1_sorted.exceptAll(test2_sorted).isEmpty())"
      ],
      "metadata": {
        "id": "NvJTzPvqa8Qp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Utdr5VGhf4d",
        "outputId": "5aba7d8a-21d4-4f95-a078-08b389f981e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".......\n",
            "----------------------------------------------------------------------\n",
            "Ran 7 tests in 38.776s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}