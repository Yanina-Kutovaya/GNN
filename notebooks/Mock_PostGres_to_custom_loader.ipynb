{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrWgc7cNo8ybNww61M6f6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanina-Kutovaya/GNN/blob/main/notebooks/Mock_PostGres_to_custom_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mock-тест для BitcoinGraphDataset\n"
      ],
      "metadata": {
        "id": "oYmxF3pZlp_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестовый класс TestBitcoinGraphDataset охватывает большинство аспектов работы класса BitcoinGraphDataset.\n",
        "\n",
        "Цели тестов:\n",
        "\n",
        "1. ```test_neighbor_sampling``` - Проверить семплирование окрестностей узлов\n",
        "2. ```test_minimal_neighborhood``` -  Проверить обработку минимальных данных.\n",
        "3. ```test_sampling_errors``` - Проверить обработку ошибок при семплировании.\n",
        "4. ```test_sql_query_format``` - Убедиться, что SQL-запросы формируются корректно.\n",
        "5. ```test_real_data_sampling``` - Проверить обработку реальных данных.\n",
        "6. ```test_getitem_returns_correct_data``` - Проверить, что метод  ```__getitem__``` датасета корректно формирует граф с правильными тензорами признаков (```x```), индексов рёбер (```edge_index```), атрибутов рёбер (```edge_attr```) и меток классов (```y```).\n",
        "7. ```test_getitem_returns_empty_graph_when_no_edges``` - Проверить обработку отсутствия рёбер.\n",
        "8. ```test_len_returns_correct_value``` - Проверить корректность метода ```__len__```\n",
        "9. ```test_model_compatibility```- Проверить, что данные из датасета можно передать в GCN-модель.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F5p9bZPot-nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torch-geometric"
      ],
      "metadata": {
        "id": "y_ZKva9m40vD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import unittest\n",
        "from unittest.mock import patch, MagicMock\n",
        "import pandas as pd\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class BitcoinGraphDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset для загрузки графа биткоина с семплированием окрестностей.\"\"\"\n",
        "\n",
        "    def __init__(self, db_config, batch_size=32, num_hops=2, num_neighbors=5):\n",
        "        \"\"\"Инициализация датасета.\n",
        "\n",
        "        Args:\n",
        "            db_config: Конфигурация БД\n",
        "            batch_size: Размер батча\n",
        "            num_hops: Количество шагов в семплировании\n",
        "            num_neighbors: Количество соседей на шаг\n",
        "        \"\"\"\n",
        "        self.db_config = db_config\n",
        "        self.batch_size = batch_size\n",
        "        self.num_hops = num_hops\n",
        "        self.num_neighbors = num_neighbors\n",
        "        self.conn = None\n",
        "        self.cursor = None\n",
        "        self.total_nodes = 0\n",
        "\n",
        "        self._init_db_connection()\n",
        "        self.total_nodes = self._get_total_nodes() or 0\n",
        "        logger.info(f\"Инициализирован датасет с {self.total_nodes} узлами.\")\n",
        "\n",
        "    def _init_db_connection(self):\n",
        "        \"\"\"Инициализация подключения к БД.\"\"\"\n",
        "        try:\n",
        "            self.conn = psycopg2.connect(**self.db_config)\n",
        "            if isinstance(self.conn, psycopg2.extensions.connection):\n",
        "                self.cursor = self.conn.cursor()\n",
        "                logger.info(\"Успешное подключение к базе данных.\")\n",
        "            else:\n",
        "                raise TypeError(\"Подключение не является ожидаемым psycopg2 connection\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка подключения к БД: {e}\")\n",
        "            self.conn = self.cursor = None\n",
        "\n",
        "    def _get_total_nodes(self):\n",
        "        \"\"\"Получение общего количества узлов.\"\"\"\n",
        "        if not self.cursor or not isinstance(self.cursor, psycopg2.extensions.cursor):\n",
        "            return 0\n",
        "        try:\n",
        "            query = \"SELECT COUNT(*) FROM node_attributes\"\n",
        "            logger.debug(f\"Выполняется SQL-запрос: {str(query)}\")\n",
        "            self.cursor.execute(query)\n",
        "            result = self.cursor.fetchone()\n",
        "            count = result[0] if result else 0\n",
        "            logger.info(f\"Найдено {count} узлов в таблице node_attributes.\")\n",
        "            return count\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка получения количества узлов: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Размер датасета в батчах.\"\"\"\n",
        "        return (self.total_nodes + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Получение одного батча.\"\"\"\n",
        "        if not self._check_connection():\n",
        "            logger.warning(\"Соединение с БД потеряно. Возвращается пустой граф.\")\n",
        "            return self._empty_data()\n",
        "        try:\n",
        "            nodes_df = self._load_batch_nodes(idx)\n",
        "            if nodes_df.empty:\n",
        "                logger.warning(f\"Батч {idx} не содержит узлов.\")\n",
        "                return self._empty_data()\n",
        "\n",
        "            all_aliases = self._get_neighborhood_aliases(nodes_df['alias'].tolist())\n",
        "            if not all_aliases:\n",
        "                logger.warning(f\"Не удалось получить окрестности для батча {idx}.\")\n",
        "                return self._empty_data()\n",
        "\n",
        "            all_nodes_df = self._load_node_attributes(all_aliases)\n",
        "            edges_df = self._load_edges(all_aliases)\n",
        "\n",
        "            logger.info(f\"Сконструирован граф с {len(all_nodes_df)} узлами и {len(edges_df)} рёбрами.\")\n",
        "            return self._construct_graph_data(all_nodes_df, edges_df)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка при получении батча {idx}: {e}\")\n",
        "            return self._empty_data()\n",
        "\n",
        "    def _check_connection(self):\n",
        "        \"\"\"Проверка активности подключения.\"\"\"\n",
        "        return bool(self.conn and self.cursor and isinstance(self.conn, psycopg2.extensions.connection))\n",
        "\n",
        "    def _load_batch_nodes(self, idx):\n",
        "        \"\"\"Загрузка батча узлов.\"\"\"\n",
        "        offset = idx * self.batch_size\n",
        "        query = f\"\"\"\n",
        "            SELECT alias, label, degree, total_received\n",
        "            FROM node_attributes\n",
        "            LIMIT {self.batch_size} OFFSET {offset}\n",
        "        \"\"\"\n",
        "        logger.debug(f\"Загрузка батча узлов: {str(query)}\")\n",
        "        try:\n",
        "            df = pd.read_sql(query, self.conn)\n",
        "            logger.info(f\"Загружено {len(df)} узлов из батча {idx}.\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка при чтении узлов: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _get_neighborhood_aliases(self, seed_aliases):\n",
        "        \"\"\"Получение окрестностей для узлов.\"\"\"\n",
        "        if not seed_aliases:\n",
        "            logger.warning(\"Список алиасов пуст. Невозможно выполнить семплирование окрестностей.\")\n",
        "            return []\n",
        "\n",
        "        query = f\"\"\"\n",
        "            WITH RECURSIVE search_graph AS (\n",
        "                SELECT alias, 0 AS hop\n",
        "                FROM node_attributes\n",
        "                WHERE alias IN ({','.join(map(str, seed_aliases))})\n",
        "                UNION ALL\n",
        "                SELECT next_alias, sg.hop + 1\n",
        "                FROM (\n",
        "                    SELECT\n",
        "                        CASE WHEN a = sg.alias THEN b ELSE a END AS next_alias,\n",
        "                        sg.alias AS current,\n",
        "                        sg.hop,\n",
        "                        ROW_NUMBER() OVER (PARTITION BY sg.alias ORDER BY random()) AS rn\n",
        "                    FROM edge_attributes e\n",
        "                    INNER JOIN search_graph sg ON e.a = sg.alias OR e.b = sg.alias\n",
        "                    WHERE sg.hop < {self.num_hops}\n",
        "                ) sub\n",
        "                WHERE next_alias IS NOT NULL AND rn <= {self.num_neighbors}\n",
        "            )\n",
        "            SELECT DISTINCT alias FROM search_graph;\n",
        "        \"\"\"\n",
        "        logger.debug(f\"Семплирование окрестностей: {str(query)}\")\n",
        "        try:\n",
        "            self.cursor.execute(query)\n",
        "            aliases = [row[0] for row in self.cursor.fetchall()]\n",
        "            logger.info(f\"Найдено {len(aliases)} узлов в окрестности.\")\n",
        "            return aliases\n",
        "        except Exception as e:\n",
        "            logger.error(f\"SQL Error in neighborhood sampling: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _load_node_attributes(self, aliases):\n",
        "        \"\"\"Загрузка атрибутов узлов.\"\"\"\n",
        "        if not aliases:\n",
        "            return pd.DataFrame()\n",
        "        query = f\"\"\"\n",
        "            SELECT alias, label, degree, total_received\n",
        "            FROM node_attributes\n",
        "            WHERE alias IN ({','.join(map(str, aliases))})\n",
        "        \"\"\"\n",
        "        logger.debug(f\"Загрузка атрибутов узлов: {str(query)}\")\n",
        "        try:\n",
        "            df = pd.read_sql(query, self.conn)\n",
        "            logger.info(f\"Загружено {len(df)} атрибутов узлов.\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка при загрузке атрибутов узлов: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _load_edges(self, aliases):\n",
        "        \"\"\"Загрузка ребер.\"\"\"\n",
        "        if not aliases:\n",
        "            return pd.DataFrame()\n",
        "        query = f\"\"\"\n",
        "            SELECT a, b, total_sent\n",
        "            FROM edge_attributes\n",
        "            WHERE a IN ({','.join(map(str, aliases))})\n",
        "               OR b IN ({','.join(map(str, aliases))})\n",
        "        \"\"\"\n",
        "        logger.debug(f\"Загрузка ребер: {str(query)}\")\n",
        "        try:\n",
        "            df = pd.read_sql(query, self.conn)\n",
        "            logger.info(f\"Загружено {len(df)} рёбер.\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ошибка при загрузке рёбер: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _construct_graph_data(self, nodes_df, edges_df):\n",
        "        \"\"\"Построение графа из данных.\"\"\"\n",
        "        alias_to_idx = {alias: i for i, alias in enumerate(nodes_df['alias'])}\n",
        "        edges, edge_attrs = self._process_edges(edges_df, alias_to_idx)\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).T if edges else torch.zeros((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.tensor(edge_attrs, dtype=torch.float).view(-1, 1) if edge_attrs else torch.zeros((0, 1), dtype=torch.float)\n",
        "        x = torch.tensor(nodes_df[['degree', 'total_received']].fillna(0).values, dtype=torch.float)\n",
        "        y = torch.tensor(nodes_df['label'].fillna(0).values, dtype=torch.long)\n",
        "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "    def _process_edges(self, edges_df, alias_to_idx):\n",
        "        \"\"\"Обработка ребер и их атрибутов.\"\"\"\n",
        "        edges = []\n",
        "        edge_attrs = []\n",
        "        for _, row in edges_df.iterrows():\n",
        "            a_idx = alias_to_idx.get(row['a'])\n",
        "            b_idx = alias_to_idx.get(row['b'])\n",
        "            if a_idx is not None and b_idx is not None:\n",
        "                edges.append([a_idx, b_idx])\n",
        "                edge_attrs.append(row['total_sent'])\n",
        "        return edges, edge_attrs\n",
        "\n",
        "    def _empty_data(self):\n",
        "        \"\"\"Возвращает пустой граф.\"\"\"\n",
        "        logger.warning(\"Возвращён пустой граф.\")\n",
        "        return Data(\n",
        "            x=torch.tensor([], dtype=torch.float),\n",
        "            edge_index=torch.tensor([], dtype=torch.long).view(2, -1),\n",
        "            edge_attr=torch.tensor([], dtype=torch.float).view(-1, 1),\n",
        "            y=torch.tensor([], dtype=torch.long)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class TestBitcoinGraphDataset(unittest.TestCase):\n",
        "    \"\"\"Тесты для BitcoinGraphDataset.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Подготовка тестового окружения.\"\"\"\n",
        "        self.db_config = {\n",
        "            'dbname': 'test_db',\n",
        "            'user': 'test_user',\n",
        "            'password': 'test_pass',\n",
        "            'host': 'localhost',\n",
        "            'port': 5432\n",
        "        }\n",
        "\n",
        "        self.nodes_data = pd.DataFrame({\n",
        "            'alias': [1, 2, 3, 4],\n",
        "            'label': [0, 1, 0, 1],\n",
        "            'degree': [2, 3, 1, 2],\n",
        "            'total_received': [100.0, 200.0, 150.0, 300.0]\n",
        "        })\n",
        "\n",
        "        self.edges_data = pd.DataFrame({\n",
        "            'a': [1, 2, 3, 1, 4],\n",
        "            'b': [2, 3, 4, 4, 1],\n",
        "            'total_sent': [50.0, 30.0, 20.0, 40.0, 60.0]\n",
        "        })\n",
        "\n",
        "    def _setup_mock(self, mock_connect, total_nodes=4, nodes_data=None):\n",
        "        \"\"\"Настройка моков для тестов с правильными типами psycopg2.\"\"\"\n",
        "        mock_conn = MagicMock(spec=psycopg2.extensions.connection)\n",
        "        mock_cursor = MagicMock(spec=psycopg2.extensions.cursor)\n",
        "\n",
        "        mock_cursor.fetchone.return_value = [total_nodes]\n",
        "        mock_conn.cursor.return_value = mock_cursor\n",
        "        mock_connect.return_value = mock_conn\n",
        "\n",
        "        return mock_conn, mock_cursor, nodes_data if nodes_data is not None else self.nodes_data\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_neighbor_sampling(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест семплирования окрестностей.\"\"\"\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 4)\n",
        "\n",
        "        def read_sql_side_effect(query, *args):\n",
        "            if 'LIMIT' in query:\n",
        "                return self.nodes_data.head(2)\n",
        "            elif 'WHERE alias IN' in query:\n",
        "                return self.nodes_data\n",
        "            elif 'SELECT a, b' in query:\n",
        "                return self.edges_data\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        mock_read_sql.side_effect = read_sql_side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute') as mock_execute:\n",
        "            with patch.object(mock_cursor, 'fetchall', return_value=[(1,), (2,), (3,), (4,)]):\n",
        "                dataset = BitcoinGraphDataset(self.db_config, batch_size=2, num_hops=2, num_neighbors=3)\n",
        "                batch = dataset[0]\n",
        "\n",
        "                self.assertEqual(batch.x.shape[0], 4)\n",
        "                self.assertEqual(batch.edge_index.shape[1], 5)\n",
        "                self.assertEqual(batch.y.shape[0], 4)\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_minimal_neighborhood(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест минимальной окрестности.\"\"\"\n",
        "        # Создаем моки с правильными типами\n",
        "        mock_conn = MagicMock(spec=psycopg2.extensions.connection)\n",
        "        mock_cursor = MagicMock(spec=psycopg2.extensions.cursor)\n",
        "\n",
        "        mock_conn.cursor.return_value = mock_cursor\n",
        "        mock_connect.return_value = mock_conn\n",
        "\n",
        "        minimal_nodes = pd.DataFrame({\n",
        "            'alias': [1],\n",
        "            'label': [0],\n",
        "            'degree': [1],\n",
        "            'total_received': [100.0]\n",
        "        })\n",
        "\n",
        "        minimal_edges = pd.DataFrame({\n",
        "            'a': [1],\n",
        "            'b': [1],\n",
        "            'total_sent': [50.0]\n",
        "        })\n",
        "\n",
        "        def read_sql_side_effect(query, *args):\n",
        "            if 'LIMIT' in query:\n",
        "                return minimal_nodes\n",
        "            elif 'WHERE alias IN' in query:\n",
        "                return minimal_nodes\n",
        "            elif 'SELECT a, b' in query:\n",
        "                return minimal_edges\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        mock_read_sql.side_effect = read_sql_side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute'), \\\n",
        "            patch.object(mock_cursor, 'fetchall', return_value=[(1,)]):\n",
        "            dataset = BitcoinGraphDataset(self.db_config, batch_size=1, num_hops=1, num_neighbors=1)\n",
        "            batch = dataset[0]\n",
        "\n",
        "            self.assertEqual(batch.x.shape, (1, 2))\n",
        "            self.assertEqual(batch.edge_index.shape, (2, 1))\n",
        "            self.assertEqual(batch.edge_attr.shape, (1, 1))\n",
        "            self.assertEqual(batch.y.shape, (1,))\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_getitem_returns_correct_data(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест __getitem__ возвращает корректные данные.\"\"\"\n",
        "        test_nodes = self.nodes_data.head(2)  # Алиасы: 1, 2\n",
        "        mock_conn, mock_cursor, _ = self._setup_mock(mock_connect, 2)\n",
        "\n",
        "        def mock_sql_side_effect(query, *args, **kwargs):\n",
        "            if 'LIMIT' in query and 'alias' in query:\n",
        "                return test_nodes\n",
        "            elif 'WHERE alias IN' in query:\n",
        "                return test_nodes\n",
        "            elif 'SELECT a, b' in query:\n",
        "                # Возвращаем только те рёбра, где оба узла есть в test_nodes\n",
        "                edges_subset = self.edges_data[\n",
        "                    (self.edges_data['a'].isin(test_nodes['alias'])) &\n",
        "                    (self.edges_data['b'].isin(test_nodes['alias']))\n",
        "                ]\n",
        "                # Добавляем недостающее ребро, если нужно, чтобы было 2 ребра\n",
        "                if len(edges_subset) < 2:\n",
        "                    new_rows = pd.DataFrame({\n",
        "                        'a': [2],\n",
        "                        'b': [1],\n",
        "                        'total_sent': [30.0]\n",
        "                    })\n",
        "                    edges_subset = pd.concat([edges_subset, new_rows], ignore_index=True)\n",
        "                return edges_subset\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        mock_read_sql.side_effect = mock_sql_side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute'), \\\n",
        "            patch.object(mock_cursor, 'fetchall', return_value=[(1,), (2,)]):\n",
        "            dataset = BitcoinGraphDataset(\n",
        "                self.db_config,\n",
        "                batch_size=2,\n",
        "                num_hops=1,\n",
        "                num_neighbors=2\n",
        "            )\n",
        "            batch = dataset[0]\n",
        "\n",
        "        self.assertIsInstance(batch, Data)\n",
        "        self.assertEqual(batch.x.shape, (2, 2))\n",
        "        self.assertEqual(batch.edge_index.shape, (2, 2))  # Теперь точно 2 ребра\n",
        "        self.assertEqual(batch.edge_attr.shape, (2, 1))\n",
        "        self.assertEqual(batch.y.shape, (2,))\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_sampling_errors(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест обработки ошибок при семплировании окрестностей.\"\"\"\n",
        "        # Подавляем логи внутри теста\n",
        "        logger = logging.getLogger('__main__')\n",
        "        logger.setLevel(logging.CRITICAL)  # Отключаем вывод ERROR и WARNING\n",
        "\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 2)\n",
        "\n",
        "        # Настраиваем side_effect для read_sql: возвращаем данные для _load_batch_nodes и _load_node_attributes\n",
        "        def read_sql_side_effect(query, *args):\n",
        "            if 'LIMIT' in query and 'alias' in query:\n",
        "                return self.nodes_data.head(1)  # Возвращаем минимум 1 узел\n",
        "            elif 'WHERE alias IN' in query:\n",
        "                return self.nodes_data.head(1)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        mock_read_sql.side_effect = read_sql_side_effect\n",
        "\n",
        "        # Настраиваем execute так, чтобы только рекурсивный запрос выбрасывал ошибку\n",
        "        def execute_side_effect(query, *args):\n",
        "            if 'WITH RECURSIVE' in query:\n",
        "                raise Exception(\"Sampling error\")  # Только для семплирования окрестностей\n",
        "            else:\n",
        "                return None  # Остальные запросы выполняются успешно\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute') as mock_execute:\n",
        "            mock_execute.side_effect = execute_side_effect\n",
        "            dataset = BitcoinGraphDataset(self.db_config, num_hops=2, num_neighbors=2)\n",
        "            batch = dataset[0]  # Вызываем __getitem__\n",
        "\n",
        "            # Проверяем, что в случае ошибки возвращается пустой граф\n",
        "            self.assertTrue(batch.x.numel() == 0, \"Node features tensor should be empty\")\n",
        "            self.assertTrue(batch.edge_index.numel() == 0, \"Edge index tensor should be empty\")\n",
        "            self.assertTrue(batch.edge_attr.numel() == 0, \"Edge attribute tensor should be empty\")\n",
        "            self.assertTrue(batch.y.numel() == 0, \"Node labels tensor should be empty\")\n",
        "\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_sql_query_format(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест корректности формирования SQL-запросов.\n",
        "\n",
        "        Проверяет, что:\n",
        "        1. SQL-запрос семплирования окрестностей содержит правильные\n",
        "          значения параметров num_hops и num_neighbors\n",
        "        2. Подстановка параметров в рекурсивный запрос выполняется корректно\n",
        "        \"\"\"\n",
        "        # Тестовые параметры\n",
        "        test_num_hops = 3\n",
        "        test_num_neighbors = 2\n",
        "\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 2)\n",
        "\n",
        "        # Настраиваем side_effect для проверки SQL-запроса\n",
        "        def side_effect(query, *args, **kwargs):\n",
        "            \"\"\"Проверяем содержание SQL-запроса при семплировании окрестностей.\"\"\"\n",
        "            if 'WITH RECURSIVE' in query:\n",
        "                # Проверяем корректность подстановки параметров в SQL\n",
        "                self.assertIn(\n",
        "                    f\"hop < {test_num_hops}\",\n",
        "                    query,\n",
        "                    \"Запрос должен содержать условие hop < num_hops\"\n",
        "                )\n",
        "                self.assertIn(\n",
        "                    f\"rn <= {test_num_neighbors}\",\n",
        "                    query,\n",
        "                    \"Запрос должен содержать ограничение rn <= num_neighbors\"\n",
        "                )\n",
        "                return pd.DataFrame()  # Для семплирования — пустой результат\n",
        "\n",
        "            elif 'LIMIT' in query and 'alias' in query:\n",
        "                # Возвращаем тестовые данные для _load_batch_nodes\n",
        "                return self.nodes_data.head(1)  # Минимум 1 узел\n",
        "\n",
        "            elif 'WHERE alias IN' in query:\n",
        "                return self.nodes_data.head(1)  # Атрибуты этого узла\n",
        "\n",
        "            elif 'SELECT a, b' in query:\n",
        "                return pd.DataFrame()  # Можно вернуть пустые рёбра\n",
        "\n",
        "            return pd.DataFrame()  # Все остальные случаи\n",
        "\n",
        "        # Привязываем side_effect к моку\n",
        "        mock_read_sql.side_effect = side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute'), \\\n",
        "            patch.object(mock_cursor, 'fetchall', return_value=[(1,)]):\n",
        "            # Создаем экземпляр датасета с тестовыми параметрами\n",
        "            dataset = BitcoinGraphDataset(\n",
        "                self.db_config,\n",
        "                num_hops=test_num_hops,\n",
        "                num_neighbors=test_num_neighbors\n",
        "            )\n",
        "\n",
        "            # Вызываем __getitem__ (что запустит выполнение SQL-запросов)\n",
        "            batch = dataset[0]\n",
        "\n",
        "            # Проверяем, что batch существует\n",
        "            self.assertIsInstance(batch, Data)\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_real_data_sampling(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест обработки реальных данных с семплированием окрестностей.\"\"\"\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 4)\n",
        "\n",
        "        # Настраиваем side_effect для имитации SQL-запросов\n",
        "        def mock_sql_side_effect(query, *args, **kwargs):\n",
        "            \"\"\"Обрабатывает SQL-запросы и возвращает тестовые данные.\"\"\"\n",
        "            if 'LIMIT' in query and 'alias' in query:  # Загрузка батча узлов\n",
        "                return nodes_data.head(2)  # Первые 2 узла (алиасы 1 и 2)\n",
        "            elif 'IN (' in query and 'alias' in query:  # Загрузка атрибутов всех алиасов\n",
        "                return nodes_data  # Возвращаем все 4 узла\n",
        "            elif 'SELECT a, b' in query:  # Загрузка ребер\n",
        "                return self.edges_data  # Используем тестовые ребра\n",
        "            return pd.DataFrame()  # Все остальные запросы возвращают пустой DataFrame\n",
        "\n",
        "        # Привязываем side_effect к моку\n",
        "        mock_read_sql.side_effect = mock_sql_side_effect\n",
        "\n",
        "        # Настраиваем возврат алиасов из рекурсивного SQL-запроса\n",
        "        with patch.object(mock_cursor, 'execute') as mock_execute:\n",
        "            with patch.object(mock_cursor, 'fetchall', return_value=[(1,), (2,), (3,), (4,)]):\n",
        "                # Создаем экземпляр датасета с тестовыми параметрами\n",
        "                dataset = BitcoinGraphDataset(\n",
        "                    self.db_config,\n",
        "                    batch_size=2,\n",
        "                    num_hops=2,\n",
        "                    num_neighbors=3\n",
        "                )\n",
        "                # Получаем первый батч данных\n",
        "                batch = dataset[0]\n",
        "\n",
        "        # Проверяем структуру графа\n",
        "        self.assertEqual(\n",
        "            len(batch.x), 4,\n",
        "            \"Количество узлов в графе должно быть равно 4\"\n",
        "        )\n",
        "        self.assertEqual(\n",
        "            len(batch.edge_index[0]), 5,\n",
        "            \"Количество ребер в графе должно быть равно 5\"\n",
        "        )\n",
        "        # Проверяем совместимость с GCN-слоем\n",
        "        class DummyGCN(torch.nn.Module):\n",
        "            \"\"\"Простая GCN-модель для тестирования.\"\"\"\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.conv = GCNConv(2, 2)  # 2 входных признака, 2 выходных\n",
        "            def forward(self, x, edge_index):\n",
        "                return self.conv(x, edge_index)\n",
        "        # Создаем экземпляр модели\n",
        "        model = DummyGCN()\n",
        "        # Выполняем прямой проход без вычисления градиентов\n",
        "        with torch.no_grad():\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "        # Проверяем размерность выхода модели\n",
        "        self.assertEqual(\n",
        "            out.shape, (4, 2),\n",
        "            \"Размерность выхода модели должна быть (4, 2)\"\n",
        "        )\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_getitem_returns_empty_graph_when_no_edges(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест обработки случая, когда в батче нет рёбер.\n",
        "        Проверяет, что датасет корректно обрабатывает отсутствие рёбер\n",
        "        и возвращает граф с пустыми edge_index и edge_attr.\n",
        "        \"\"\"\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 2)\n",
        "\n",
        "        def side_effect(query, *args, **kwargs):\n",
        "            \"\"\"Обрабатывает SQL-запросы и возвращает тестовые данные.\"\"\"\n",
        "            if 'LIMIT' in query and 'alias' in query:  # Загрузка батча узлов\n",
        "                return nodes_data.head(2)  # Возвращаем 2 узла (алиасы 1 и 2)\n",
        "            elif 'WHERE alias IN' in query:  # Загрузка атрибутов всех алиасов\n",
        "                return nodes_data.head(2)  # Используем те же 2 узла\n",
        "            elif 'SELECT a, b' in query:  # Загрузка рёбер (возвращаем пустой DataFrame)\n",
        "                return pd.DataFrame(columns=['a', 'b', 'total_sent'])\n",
        "            return pd.DataFrame()  # Все остальные запросы возвращают пустой DataFrame\n",
        "\n",
        "        # Привязываем side_effect к моку\n",
        "        mock_read_sql.side_effect = side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute'), \\\n",
        "            patch.object(mock_cursor, 'fetchall', return_value=[(1,), (2,)]):\n",
        "            # Создаем экземпляр датасета с тестовыми параметрами\n",
        "            dataset = BitcoinGraphDataset(\n",
        "                self.db_config,\n",
        "                batch_size=2,\n",
        "                num_hops=1,\n",
        "                num_neighbors=2\n",
        "            )\n",
        "            # Получаем первый батч данных\n",
        "            batch = dataset[0]\n",
        "\n",
        "        # Проверяем структуру графа\n",
        "        self.assertIsInstance(batch, Data, \"Батч должен быть экземпляром torch_geometric.data.Data\")\n",
        "        self.assertEqual(\n",
        "            batch.x.shape, (2, 2),\n",
        "            \"Размерность признаков узлов должна быть (2, 2)\"\n",
        "        )\n",
        "        self.assertEqual(\n",
        "            batch.edge_index.shape, (2, 0),\n",
        "            \"Размерность edge_index должна быть (2, 0) для пустых рёбер\"\n",
        "        )\n",
        "        self.assertEqual(\n",
        "            batch.edge_attr.shape, (0, 1),\n",
        "            \"Размерность edge_attr должна быть (0, 1) для пустых рёбер\"\n",
        "        )\n",
        "        self.assertEqual(\n",
        "            batch.y.shape, (2,),\n",
        "            \"Размерность меток должна быть (2,)\"\n",
        "        )\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    def test_len_returns_correct_value(self, mock_connect):\n",
        "        \"\"\"Тест корректного вычисления длины датасета.\n",
        "\n",
        "        Проверяет, что метод __len__ возвращает правильное количество батчей:\n",
        "        - Учитывает остаток от деления (округление вверх)\n",
        "        - Работает при различных значениях batch_size и total_nodes\n",
        "        \"\"\"\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 65)\n",
        "\n",
        "        # Тестовый случай: 65 узлов, batch_size=32\n",
        "        # Ожидаемое значение: (65 + 32 - 1) // 32 = 96 // 32 = 3\n",
        "        dataset = BitcoinGraphDataset(self.db_config, batch_size=32)\n",
        "        self.assertEqual(\n",
        "            len(dataset), 3,\n",
        "            \"Длина датасета должна быть равна 3 для 65 узлов и batch_size=32\"\n",
        "        )\n",
        "\n",
        "        # Дополнительные проверки для других значений\n",
        "        # Тестовый случай: 64 узла, batch_size=32 (точное деление)\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 64)\n",
        "        dataset = BitcoinGraphDataset(self.db_config, batch_size=32)\n",
        "        self.assertEqual(\n",
        "            len(dataset), 2,\n",
        "            \"Длина датасета должна быть равна 2 для 64 узлов и batch_size=32\"\n",
        "        )\n",
        "\n",
        "        # Тестовый случай: 1 узел, batch_size=32\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 1)\n",
        "        dataset = BitcoinGraphDataset(self.db_config, batch_size=32)\n",
        "        self.assertEqual(\n",
        "            len(dataset), 1,\n",
        "            \"Длина датасета должна быть равна 1 для 1 узла и batch_size=32\"\n",
        "        )\n",
        "\n",
        "        # Тестовый случай: 0 узлов (не поддерживается в _setup_mock, но проверяем)\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 0)\n",
        "        dataset = BitcoinGraphDataset(self.db_config, batch_size=32)\n",
        "        self.assertEqual(\n",
        "            len(dataset), 0,\n",
        "            \"Длина датасета должна быть равна 0 для 0 узлов\"\n",
        "        )\n",
        "\n",
        "    @patch('psycopg2.connect')\n",
        "    @patch('pandas.read_sql')\n",
        "    def test_model_compatibility(self, mock_read_sql, mock_connect):\n",
        "        \"\"\"Тест совместимости датасета с GCN-моделью.\"\"\"\n",
        "        # Подготавливаем моки для подключения к БД\n",
        "        mock_conn, mock_cursor, nodes_data = self._setup_mock(mock_connect, 2)\n",
        "        # Явно определяем test_nodes\n",
        "        test_nodes = self.nodes_data.head(2)  # Первые 2 узла (алиасы 1 и 2)\n",
        "\n",
        "        def side_effect(query, *args, **kwargs):\n",
        "            \"\"\"Обрабатывает SQL-запросы и возвращает тестовые данные.\"\"\"\n",
        "            if 'LIMIT' in query and 'alias' in query:  # Загрузка батча узлов\n",
        "                return test_nodes\n",
        "            elif 'WHERE alias IN' in query:  # Загрузка атрибутов узлов по алиасам\n",
        "                return test_nodes  # Используем те же 2 узла\n",
        "            elif 'WITH RECURSIVE' in query:  # Семплирование окрестностей\n",
        "                return test_nodes  # Используем те же 2 узла\n",
        "            elif 'SELECT a, b' in query:  # Загрузка рёбер\n",
        "                # Берем первые 2 ребра и корректируем их, чтобы они соответствовали test_nodes\n",
        "                edges_subset = self.edges_data.head(2).copy()\n",
        "                edges_subset['a'] = edges_subset['a'].apply(lambda x: x if x in [1,2] else 1)\n",
        "                edges_subset['b'] = edges_subset['b'].apply(lambda x: x if x in [1,2] else 2)\n",
        "                new_row = pd.DataFrame({'a': [2], 'b': [1], 'total_sent': [30.0]})\n",
        "                edges_subset = pd.concat([edges_subset, new_row], ignore_index=True)\n",
        "                return edges_subset\n",
        "            return pd.DataFrame()  # Все остальные запросы возвращают пустой DataFrame\n",
        "\n",
        "        # Привязываем side_effect к моку\n",
        "        mock_read_sql.side_effect = side_effect\n",
        "\n",
        "        with patch.object(mock_cursor, 'execute'), \\\n",
        "            patch.object(mock_cursor, 'fetchall', return_value=[(1,), (2,)]):\n",
        "            # Создаем экземпляр датасета с тестовыми параметрами\n",
        "            dataset = BitcoinGraphDataset(\n",
        "                self.db_config,\n",
        "                batch_size=2,\n",
        "                num_hops=1,\n",
        "                num_neighbors=2\n",
        "            )\n",
        "            # Получаем первый батч данных\n",
        "            batch = dataset[0]\n",
        "\n",
        "        # Проверяем структуру графа\n",
        "        self.assertIsInstance(batch, Data, \"Батч должен быть экземпляром torch_geometric.data.Data\")\n",
        "        self.assertEqual(\n",
        "            batch.x.shape, (2, 2),\n",
        "            \"Размерность признаков узлов должна быть (2, 2)\"\n",
        "        )\n"
      ],
      "metadata": {
        "id": "8BaQX7scIlPu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IepA_nb4pur1",
        "outputId": "a2eae1f0-622c-4c60-80d2-d1d2ddc1aacb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".........\n",
            "----------------------------------------------------------------------\n",
            "Ran 9 tests in 0.260s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}